{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgZOU+G/YvtFWDelYexprF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irshandyaditya/machine_learning/blob/main/P10/Praktikum_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "1-rYXsX2anWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YsRMhm96ZTnk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ],
      "metadata": {
        "id": "LtqfXlogaX9w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup input pipeline**"
      ],
      "metadata": {
        "id": "So_x3F-ea6JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwyrWtshayup",
        "outputId": "d2b45b1e-7187-4394-d450-de75a38591c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengembalikan dataset (teks, pasangan label):"
      ],
      "metadata": {
        "id": "EJ9a4SUNbx53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb6yLr0kbQcG",
        "outputId": "58ef5eef-e4f3-45e5-cc27-75aca2355b84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acak data untuk pelatihan dan membuat kumpulan pasangan (teks, label)"
      ],
      "metadata": {
        "id": "knuf6mUNctp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX4EMBHZb5Wi",
        "outputId": "58b781e8-912e-4b3a-a169-46ed75a06548"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b\"I found myself very caught up in this movie, at least at the beginning, and any credit I give to this movie, is Lacey Chabert, she was fantastic!! But thats where it ends. I seem to be very good at figuring out who the killer is, and I like it when a movie is able to completely baffel me, but I felt out and out lied to, they whole time they lead you in one direction and then suddenly they decided to go in a completely different direction at the end, they gave no hit to it at all, thats not misleading that very bad writing and planning, someone did not think at all!<br /><br />I felt the movie would have been much better if they had stuck to the plot that the lead you on, they also seemed to not answer anything, why did Jane(maria) burn down the professor's house.<br /><br />Its a great pity as I felt it started out as a relatively good movie.\"\n",
            " b\"This was my first introduction to the world of Bollywood and I'm now hooked! Okay so it requires adoption of a different mindset to watching US films but once you allow yourself the pleasure of enjoying it for what it is you won't be disappointed. The songs are superb, melodic and very catchy. The actors are visually compelling especially Karisma Kapoor who is surely one of the most beautiful actresses anywhere in the film world. Locations, colour are spellbinding. If you want something different and are looking to be uplifted, cheered up and stimulated I recommend you catch this movie.\"\n",
            " b'Fay, the sister of the notorious Nobel prize-winning smut poet Simon Grim, still loves Henry Fool. Their son receives an ingenious orgy-in-a-box from an undisclosed sender and a chase across three continents ensues, involving a supremely sad-sack collection of government agents, terrorists, flight attendants, and bellhops.<br /><br />Parker Posey delivers a perfectly timed comic performance, including some brilliant physical work. With strong contributions by Jasmin Tabatabai and Saffron Burrows, Fay Grim proves in the best Billy Wilder tradition that nothing is funnier than a beautiful woman in trouble.<br /><br />Another good score by Hartley (and thanks in the credits to the American Academy in Berlin, where Hartley served as a fellow in Fall 2004).']\n",
            "\n",
            "labels:  [0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Buat Teks Encoder**"
      ],
      "metadata": {
        "id": "pkDioOGjdbjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "metadata": {
        "id": "rzziF4pncn08"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e6GHV7IdqmH",
        "outputId": "d168470f-25bc-46cc-d41d-3b760a878908"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ-hkZY7d8Qe",
        "outputId": "fadd79c4-ab49-4648-8eae-f041f9abca04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10, 249, 532, ...,   0,   0,   0],\n",
              "       [ 11,  14,  56, ...,   0,   0,   0],\n",
              "       [  1,   2, 805, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4glfWbKJeQde",
        "outputId": "ff87e062-6bc3-4c94-ad1c-5e955834ab81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b\"I found myself very caught up in this movie, at least at the beginning, and any credit I give to this movie, is Lacey Chabert, she was fantastic!! But thats where it ends. I seem to be very good at figuring out who the killer is, and I like it when a movie is able to completely baffel me, but I felt out and out lied to, they whole time they lead you in one direction and then suddenly they decided to go in a completely different direction at the end, they gave no hit to it at all, thats not misleading that very bad writing and planning, someone did not think at all!<br /><br />I felt the movie would have been much better if they had stuck to the plot that the lead you on, they also seemed to not answer anything, why did Jane(maria) burn down the professor's house.<br /><br />Its a great pity as I felt it started out as a relatively good movie.\"\n",
            "Round-trip:  i found myself very [UNK] up in this movie at least at the beginning and any [UNK] i give to this movie is [UNK] [UNK] she was fantastic but thats where it ends i seem to be very good at [UNK] out who the killer is and i like it when a movie is able to completely [UNK] me but i felt out and out [UNK] to they whole time they lead you in one direction and then [UNK] they decided to go in a completely different direction at the end they gave no hit to it at all thats not [UNK] that very bad writing and [UNK] someone did not think at [UNK] br i felt the movie would have been much better if they had [UNK] to the plot that the lead you on they also seemed to not [UNK] anything why did [UNK] [UNK] down the [UNK] [UNK] br its a great [UNK] as i felt it started out as a [UNK] good movie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
            "\n",
            "Original:  b\"This was my first introduction to the world of Bollywood and I'm now hooked! Okay so it requires adoption of a different mindset to watching US films but once you allow yourself the pleasure of enjoying it for what it is you won't be disappointed. The songs are superb, melodic and very catchy. The actors are visually compelling especially Karisma Kapoor who is surely one of the most beautiful actresses anywhere in the film world. Locations, colour are spellbinding. If you want something different and are looking to be uplifted, cheered up and stimulated I recommend you catch this movie.\"\n",
            "Round-trip:  this was my first [UNK] to the world of [UNK] and im now [UNK] okay so it [UNK] [UNK] of a different [UNK] to watching us films but once you [UNK] yourself the [UNK] of [UNK] it for what it is you wont be disappointed the songs are superb [UNK] and very [UNK] the actors are [UNK] [UNK] especially [UNK] [UNK] who is [UNK] one of the most beautiful [UNK] [UNK] in the film world [UNK] [UNK] are [UNK] if you want something different and are looking to be [UNK] [UNK] up and [UNK] i recommend you [UNK] this movie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
            "\n",
            "Original:  b'Fay, the sister of the notorious Nobel prize-winning smut poet Simon Grim, still loves Henry Fool. Their son receives an ingenious orgy-in-a-box from an undisclosed sender and a chase across three continents ensues, involving a supremely sad-sack collection of government agents, terrorists, flight attendants, and bellhops.<br /><br />Parker Posey delivers a perfectly timed comic performance, including some brilliant physical work. With strong contributions by Jasmin Tabatabai and Saffron Burrows, Fay Grim proves in the best Billy Wilder tradition that nothing is funnier than a beautiful woman in trouble.<br /><br />Another good score by Hartley (and thanks in the credits to the American Academy in Berlin, where Hartley served as a fellow in Fall 2004).'\n",
            "Round-trip:  [UNK] the sister of the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] still [UNK] [UNK] [UNK] their son [UNK] an [UNK] [UNK] from an [UNK] [UNK] and a [UNK] across three [UNK] [UNK] [UNK] a [UNK] [UNK] [UNK] of [UNK] [UNK] [UNK] [UNK] [UNK] and [UNK] br [UNK] [UNK] [UNK] a perfectly [UNK] comic performance including some brilliant [UNK] work with strong [UNK] by [UNK] [UNK] and [UNK] [UNK] [UNK] [UNK] [UNK] in the best [UNK] [UNK] [UNK] that nothing is [UNK] than a beautiful woman in [UNK] br another good score by [UNK] and [UNK] in the credits to the american [UNK] in [UNK] where [UNK] [UNK] as a [UNK] in fall [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Buat Model**"
      ],
      "metadata": {
        "id": "mJwe40EXel4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "LMC3m5b6eVd5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnnVecVheqKy",
        "outputId": "abfcc79f-7fa5-44eb-c7fd-f7c221c8f75b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ['The movie was cool. The animation and the graphics ',\n",
        "               'were out of this world. I would recommend this movie.']\n",
        "\n",
        "# Lakukan prediksi\n",
        "text_tensor = tf.convert_to_tensor(sample_text)\n",
        "predictions = model.predict(text_tensor)\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0m3A_1yevyy",
        "outputId": "a4300b08-eb99-4d0c-92a3-76b3f4aabfc6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "[2.6549213e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "text_padding = padding + \" \" .join(sample_text)\n",
        "text_padding_convert = tf.convert_to_tensor([text_padding])\n",
        "predictions = model.predict(text_padding_convert)\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0baYjOHufBkb",
        "outputId": "82b3fc88-817d-48f3-9b2c-1f7a1a4da372"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
            "[0.01217136]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "S-1hsFSDxghN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "JpDCvqey1CKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        " validation_data=test_dataset,\n",
        " validation_steps=30)"
      ],
      "metadata": {
        "id": "6lgfzTwL06Qm",
        "outputId": "52d61ee8-e236-4e3d-da10-3a700896ba76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m169/391\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:31\u001b[0m 2s/step - accuracy: 0.4873 - loss: 0.6928"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mounEDv51Id2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}